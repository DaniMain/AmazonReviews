{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YmIYaBRYVe79"
   },
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PYCmg2gIYhka"
   },
   "source": [
    "First, let's define a function to preprocess frases using stemming and removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2353,
     "status": "ok",
     "timestamp": 1570442219966,
     "user": {
      "displayName": "Daniele Mainella",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBTWNOc0oxkHhJk5ULS254X8ien6i4qKl7G1tMuZw=s64",
      "userId": "04877843810688149002"
     },
     "user_tz": -120
    },
    "id": "zrCkQMC9Ythc",
    "outputId": "783cff06-5b89-4e43-8567-6ad58c12818c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "porter_stemmer = PorterStemmer()\n",
    "en_stops = set(stopwords.words('english'))\n",
    "\n",
    "#binary search to improve efficency\n",
    "def binary_search(e,l,inizio,fine):\n",
    "  if inizio>fine or e<l[inizio] or e>l[fine-1]:\n",
    "    return False\n",
    "  else:\n",
    "    mezzo=int((inizio+fine)/2)\n",
    "    m=l[mezzo]\n",
    "    if e==m:\n",
    "      return True\n",
    "    elif e>m:\n",
    "      return binary_search(e,l,mezzo,fine)\n",
    "    else:\n",
    "      return binary_search(e,l,inizio,mezzo)\n",
    "\n",
    "#removing symbols and adding space after them\n",
    "def prepreprocess(frase):\n",
    "  s=''\n",
    "  syms=['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z','è','é','à','ò','ì','ù']\n",
    "  for char in frase:\n",
    "    if char not in syms:\n",
    "      s+=' '\n",
    "    else:\n",
    "      s+=char\n",
    "  return s\n",
    "\n",
    "#preprocess using prepreprocess fase and stemming and removing stopwords\n",
    "def preprocess(frase,en_words):\n",
    "  l=[]\n",
    "  for word in prepreprocess(frase.lower()).split(' '):\n",
    "    w=word.lower()\n",
    "    if w not in en_stops and len(w)>2 and binary_search(w,en_words,0,len(en_words)):\n",
    "        l.append(porter_stemmer.stem(w))\n",
    "  return repr(' '.join(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gOboDiejGra4"
   },
   "source": [
    "Let's load now the data frame, saved as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7z3J9YbMAQUg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('../data/reviews_Video_Games_5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ZqSrHJLv_6W"
   },
   "source": [
    "Now we can preprocess the whole data set using previous function. Preprocess is calculated on the concatenation of summary and review text and result is added in a new column ('text')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nE-MNzrZv8of"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# en_words=sorted(open('/content/drive/My Drive/uni/ml/progetto/en_words.txt', 'r').read().lower().split('\\n'))\n",
    "\n",
    "# df['text']=df['summary']+' '+df['reviewText']\n",
    "# df['text']=df['text'].apply(lambda x:preprocess(str(x.lower()),en_words))\n",
    "\n",
    "en_words=sorted(open('../data/en_words.txt', 'r').read().lower().split('\\n'))\n",
    "reader = csv.reader(open('../data/reviews_Video_Games_5.csv','rt'))\n",
    "\n",
    "new_df=[]\n",
    "tags=next(reader)\n",
    "for row in reader:\n",
    "  row[9]=preprocess(str(row[6]+' '+row[4]),en_words)\n",
    "  new_df.append(row)\n",
    "\n",
    "df=pd.DataFrame(new_df, columns=tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cbryUMF5uyU4"
   },
   "source": [
    "This is only for the first time. The result of previous code is a new data frame that contains a new field where there is the result of preprocessing. In order to don't repeat it another time (preprocess is too slow) we saved it on a new csv file from which we can start the rest of the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7o25ibg3FCCb"
   },
   "outputs": [],
   "source": [
    "df.to_csv('../data/reviews_Video_Games_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kY5T1HjQr4ZA"
   },
   "source": [
    "Now we add a cleaning phase in which all reviews don't received a sufficient number of votes are discarded. If a review has received more than 10 votes, it's saved in a new data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X_CbKDQEp79M"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "reader=csv.reader(open('../data/reviews_Video_Games_5.csv','rt'))\n",
    "\n",
    "new_df=[]\n",
    "threshold=10\n",
    "\n",
    "tags=next(reader)\n",
    "\n",
    "for row in reader:\n",
    "  totVotes=int(row[3].split(',')[1][:-1])\n",
    "  if(totVotes>=threshold):\n",
    "    new_df.append(row)\n",
    "\n",
    "df=pd.DataFrame(new_df, columns=tags)\n",
    "df.to_csv('../data/reviews_Video_Games_5-over10.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "u0KhbQucWAc4"
   ],
   "name": "AmazonReviews.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
