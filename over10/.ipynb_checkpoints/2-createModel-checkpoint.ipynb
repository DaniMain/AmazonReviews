{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23876,
     "status": "ok",
     "timestamp": 1570446877880,
     "user": {
      "displayName": "Daniele Mainella",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBTWNOc0oxkHhJk5ULS254X8ien6i4qKl7G1tMuZw=s64",
      "userId": "04877843810688149002"
     },
     "user_tz": -120
    },
    "id": "Vq_ZK1vw4abE",
    "outputId": "56d81812-d58f-4227-e267-b1f901703565"
   },
   "source": [
    "# Create Data Set by TF-IDF model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mMLO7Ib_rjvG"
   },
   "source": [
    "We now need to create the vocabulary and start the counting process. We can use the CountVectorizer to create a vocabulary from all the text in our df['text'] followed by the counts of words in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R9NCxZ6R4o8F"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('../data/reviews_Video_Games_5-over10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6292,
     "status": "ok",
     "timestamp": 1570446890753,
     "user": {
      "displayName": "Daniele Mainella",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBTWNOc0oxkHhJk5ULS254X8ien6i4qKl7G1tMuZw=s64",
      "userId": "04877843810688149002"
     },
     "user_tz": -120
    },
    "id": "X0AyYCdkro9N",
    "outputId": "2978c02d-3b76-4642-ff0e-e0d25787556f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['come', 'vis', 'viser', 'visest'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "\n",
    "def get_stop_words(stop_file_path):\n",
    "  \"\"\"load stop words \"\"\"    \n",
    "  with open(stop_file_path, 'r', encoding=\"utf-8\") as f:\n",
    "    stopwords = f.readlines()\n",
    "    stop_set = set(m.strip() for m in stopwords)\n",
    "  return frozenset(stop_set)\n",
    "\n",
    "#load a set of stop words\n",
    "stopwords=get_stop_words('../data/stopwords.txt')\n",
    "\n",
    "#get the text column \n",
    "docs=df['text'].tolist()\n",
    "\n",
    "#create a vocabulary of words, \n",
    "#ignore words that appear in 99,999999% of documents, \n",
    "#eliminate stop words\n",
    "cv=CountVectorizer(stop_words=stopwords)\n",
    "word_count_vector=cv.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yEkWNADisUR1"
   },
   "source": [
    "Its now time to compute the IDF values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EX35FtVRJiMe"
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# tfidf = TfidfVectorizer()\n",
    "# features = tfidf.fit_transform(df['text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1072,
     "status": "ok",
     "timestamp": 1570446893375,
     "user": {
      "displayName": "Daniele Mainella",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBTWNOc0oxkHhJk5ULS254X8ien6i4qKl7G1tMuZw=s64",
      "userId": "04877843810688149002"
     },
     "user_tz": -120
    },
    "id": "SqMZcerIsU7H",
    "outputId": "5cf35ad7-1d21-4974-b923-5de8c5d8cc9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit(word_count_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T1-48ZioscT6"
   },
   "source": [
    "We are now ready to compute TF-IDF and then extract top keywords from the TF-IDF vectors. First, let's separate data set from test set to extract top keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cXYTi3iNlokb"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "ds=[]\n",
    "ts=[]\n",
    "\n",
    "reader = csv.reader(open('../data/reviews_Video_Games_5-over10.csv','rt'))\n",
    "\n",
    "tags=next(reader)\n",
    "for row in reader:\n",
    "  if random.randint(1,40)>1:\n",
    "    ds.append(row)\n",
    "  else:\n",
    "    ts.append(row)\n",
    "    \n",
    "dataset=pd.DataFrame(ds, columns=tags)\n",
    "testset=pd.DataFrame(ts, columns=tags)\n",
    "\n",
    "# get test docs into a list\n",
    "docs_test=testset['text'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yuGRTFJJqdkx"
   },
   "source": [
    "The next step is to compute the tf-idf value for a given document in our test set that generates a vector of tf-idf scores. Next, we sort the words in the vector in descending order of tf-idf values and then iterate over to extract the top-n keywords.We are extracting keywords for the first document in our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HuKnsUqpqey1"
   },
   "outputs": [],
   "source": [
    "def sort_coo(coo_matrix):\n",
    "  tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "  return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    " \n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "  \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "  #use only topn items from vector\n",
    "  sorted_items = sorted_items[:topn] \n",
    "  score_vals = []\n",
    "  feature_vals = []\n",
    "  # word index and corresponding tf-idf score\n",
    "  for idx, score in sorted_items:\n",
    "    #keep track of feature name and its corresponding score\n",
    "    score_vals.append(round(score, 3))\n",
    "    feature_vals.append(feature_names[idx])\n",
    "  #create a tuples of feature,score\n",
    "  #results = zip(feature_vals,score_vals)\n",
    "  results= {}\n",
    "  for idx in range(len(feature_vals)):\n",
    "    results[feature_vals[idx]]=score_vals[idx]    \n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vu4ua92gaOiF"
   },
   "outputs": [],
   "source": [
    "# dizionario={}\n",
    "# for e in cv.get_feature_names():\n",
    "#   dizionario[e]=0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZAA5J6p3ElNh"
   },
   "source": [
    "Now we are ready to compute tf-idf values for words in each row. We create a list which each element is a dictionary that contains the word as a key and the values is the tf-idf value of that word. Each dictionary is reffered to a single review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 676788,
     "status": "ok",
     "timestamp": 1570447580502,
     "user": {
      "displayName": "Daniele Mainella",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBTWNOc0oxkHhJk5ULS254X8ien6i4qKl7G1tMuZw=s64",
      "userId": "04877843810688149002"
     },
     "user_tz": -120
    },
    "id": "-foFZHVKcN0u",
    "outputId": "1bcafe05-06e0-4083-e287-37ef1a1faed1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "feature_names=cv.get_feature_names()\n",
    "\n",
    "i=0\n",
    "dicts=[]\n",
    "for doc in df['text'].tolist():\n",
    "  if(i%10000==0):\n",
    "    print(i)\n",
    "  #generate tf-idf for the given document\n",
    "  tf_idf_vector=tfidf_transformer.transform(cv.transform([doc])) \n",
    "  #sort the tf-idf vectors by descending order of scores\n",
    "  sorted_items=sort_coo(tf_idf_vector.tocoo()) \n",
    "  #extract all items from document\n",
    "  keywords=extract_topn_from_vector(feature_names,sorted_items,len(doc))\n",
    "  d={}\n",
    "  for e in cv.get_feature_names():\n",
    "    if e in keywords:\n",
    "      d[e]=keywords[e]\n",
    "  dicts.append(d)\n",
    "  i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 945,
     "status": "ok",
     "timestamp": 1570448884598,
     "user": {
      "displayName": "Daniele Mainella",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBTWNOc0oxkHhJk5ULS254X8ien6i4qKl7G1tMuZw=s64",
      "userId": "04877843810688149002"
     },
     "user_tz": -120
    },
    "id": "HVVLZmD2GU3A",
    "outputId": "0a53368b-b2a0-4252-dde8-ccc2a0807f3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25895"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rS3ZpBPUGYn7"
   },
   "source": [
    "In order to don't create a data frame with 35681 attributes, we take only the top 100 words most used in all reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gA8TnvuFJEQE"
   },
   "outputs": [],
   "source": [
    "def min_list(l):\n",
    "  m=l[0]\n",
    "  for e in l:\n",
    "    if e<m:\n",
    "      m=e\n",
    "  return m\n",
    "\n",
    "def remove_value(d,v):\n",
    "  keys=d.keys()\n",
    "  for e in keys:\n",
    "    if d[e]==v:\n",
    "      del d[e]\n",
    "      break\n",
    "      \n",
    "keycount={}\n",
    "for e in cv.get_feature_names():\n",
    "  keycount[e]=0\n",
    "for d in dicts:\n",
    "  keys=d.keys()\n",
    "  for k in keys:\n",
    "    keycount[k]+=1\n",
    "\n",
    "minv=0\n",
    "top100={}\n",
    "for k in keycount.keys():\n",
    "  if len(top100)<100:\n",
    "    top100[k]=keycount[k]\n",
    "    minv=min_list(list(top100.values()))\n",
    "  else:\n",
    "    if keycount[k]>minv:\n",
    "      remove_value(top100,minv)\n",
    "      top100[k]=keycount[k]\n",
    "      minv=min_list(list(top100.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U64lx-zeqhpw"
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# # tfidf = TfidfVectorizer()\n",
    "# # features = tfidf.fit_transform(df['text'].tolist())\n",
    "\n",
    "# # you only needs to do this once, this is a mapping of index to \n",
    "# feature_names=cv.get_feature_names()\n",
    " \n",
    "# # get the document that we want to extract keywords from\n",
    "# r=random.randint(0,len(ts))\n",
    "# doc=docs_test[r]\n",
    " \n",
    "# #generate tf-idf for the given document\n",
    "# tf_idf_vector=tfidf_transformer.transform(cv.transform([doc]))\n",
    " \n",
    "# #sort the tf-idf vectors by descending order of scores\n",
    "# sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    " \n",
    "# #extract only the top n; n here is 10\n",
    "# keywords=extract_topn_from_vector(feature_names,sorted_items,len(doc))\n",
    " \n",
    "# # now print the results\n",
    "# print(\"\\n=====Doc=====\")\n",
    "# print(r,len(doc.split(' ')),doc)\n",
    "# print(\"\\n===Keywords===\")\n",
    "# for k in keywords:\n",
    "#   print(k,keywords[k])\n",
    "# print(len(keywords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f18uh16eHoaZ"
   },
   "source": [
    "We are now ready to create the data frame which: first column is the review text, the second one is the utility (calculated as the ratio between usefull rates and total rate and is 1 if this ratio is more equal than 0.7, 0 otherwise), the other columns are tf-idf value of each word in the columns in each review (if the word isn't in the review text value is 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yiBfAwOi4-6h"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "reader = csv.reader(open('../data/reviews_Video_Games_5-over10.csv','rt'))\n",
    "\n",
    "dataframe=[]\n",
    "tags=['text','utility']\n",
    "\n",
    "for e in list(top100.keys()):\n",
    "  tags.append(e)\n",
    "\n",
    "def utility(a,b):\n",
    "  if b==0.0: return 0.0\n",
    "  return a/b\n",
    "\n",
    "i=0\n",
    "next(reader)\n",
    "for row in reader:\n",
    "  r=[]\n",
    "  r.append(row[9])\n",
    "  u=utility(float(eval(row[3])[0]),float(eval(row[3])[1]))\n",
    "  if u>=0.7:\n",
    "    r.append(1)\n",
    "  else:\n",
    "    r.append(0)\n",
    "  for e in top100.keys():\n",
    "    if e in dicts[i].keys():\n",
    "      r.append(dicts[i][e])\n",
    "    else:\n",
    "      r.append(0)\n",
    "  dataframe.append(r)\n",
    "  i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Tl107CJJRne"
   },
   "source": [
    "This is only for the first time we create the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ksSdN9Mk6qGR"
   },
   "outputs": [],
   "source": [
    "DF=pd.DataFrame(dataframe, columns=tags)\n",
    "DF.to_csv('../data/reviews_Video_Games_5-over10-data_frame.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 780
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1249,
     "status": "ok",
     "timestamp": 1570448989087,
     "user": {
      "displayName": "Daniele Mainella",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBTWNOc0oxkHhJk5ULS254X8ien6i4qKl7G1tMuZw=s64",
      "userId": "04877843810688149002"
     },
     "user_tz": -120
    },
    "id": "PZ7OJ0NxDbB3",
    "outputId": "3a247f41-59bc-4772-eeea-a8db6c319c4c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>utility</th>\n",
       "      <th>actual</th>\n",
       "      <th>anoth</th>\n",
       "      <th>back</th>\n",
       "      <th>bad</th>\n",
       "      <th>best</th>\n",
       "      <th>big</th>\n",
       "      <th>bit</th>\n",
       "      <th>buy</th>\n",
       "      <th>...</th>\n",
       "      <th>time</th>\n",
       "      <th>tri</th>\n",
       "      <th>turn</th>\n",
       "      <th>version</th>\n",
       "      <th>way</th>\n",
       "      <th>well</th>\n",
       "      <th>work</th>\n",
       "      <th>world</th>\n",
       "      <th>worth</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'pay unlock content think instal game struggl ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'awesom game crash frequent got version instea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'step dirt terrif love play dirt thought graph...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'fun pretti fun game buy car track onlin store...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'best graphic game far must gamer realli hit h...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  utility  actual  anoth  \\\n",
       "0  'pay unlock content think instal game struggl ...        0     0.0  0.052   \n",
       "1  'awesom game crash frequent got version instea...        1     0.0  0.000   \n",
       "2  'step dirt terrif love play dirt thought graph...        1     0.0  0.000   \n",
       "3  'fun pretti fun game buy car track onlin store...        1     0.0  0.000   \n",
       "4  'best graphic game far must gamer realli hit h...        1     0.0  0.000   \n",
       "\n",
       "   back  bad   best  big  bit    buy  ...   time    tri   turn  version  \\\n",
       "0   0.0  0.0  0.000  0.0  0.0  0.091  ...  0.000  0.000  0.000    0.000   \n",
       "1   0.0  0.0  0.000  0.0  0.0  0.046  ...  0.069  0.047  0.029    0.147   \n",
       "2   0.0  0.0  0.000  0.0  0.0  0.000  ...  0.000  0.000  0.000    0.000   \n",
       "3   0.0  0.0  0.000  0.0  0.0  0.138  ...  0.052  0.000  0.000    0.000   \n",
       "4   0.0  0.0  0.105  0.0  0.0  0.148  ...  0.000  0.000  0.000    0.000   \n",
       "\n",
       "     way   well   work  world  worth   year  \n",
       "0  0.000  0.000  0.000    0.0  0.000  0.000  \n",
       "1  0.000  0.020  0.024    0.0  0.028  0.052  \n",
       "2  0.000  0.049  0.000    0.0  0.000  0.000  \n",
       "3  0.064  0.000  0.000    0.0  0.000  0.000  \n",
       "4  0.000  0.044  0.000    0.0  0.000  0.000  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# DF=pd.read_csv('../data/reviews_Video_Games_5-over10-data_frame.csv')\n",
    "DF.head()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "create-model-and-dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
